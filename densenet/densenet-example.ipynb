{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e081b7",
   "metadata": {},
   "source": [
    "# Sparsifying DenseNet121 from Scratch (Flower102)\n",
    "\n",
    "In this example, we will demonstrate how to sparsify an image classification model from scratch using SparseML's PyTorch integration. We train and prune [DenseNet121](https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html) on the downstream [Oxford Flower 102 dataset](https://pytorch.org/vision/main/generated/torchvision.datasets.Flowers102.html#:~:text=Oxford%20102%20Flower%20is%20an,scale%2C%20pose%20and%20light%20variations) using the Global Magnitude Pruning algorithm. \n",
    "\n",
    "## Agenda\n",
    "\n",
    "There are a few steps:\n",
    "\n",
    " 1. Setup the dataset\n",
    " 2. Setup the PyTorch training loop\n",
    " 3. Train a dense version of DenseNet121\n",
    " 4. Run the GMP pruning algorithm and QAT quantization algorithm on the dense model\n",
    " \n",
    "## Installation\n",
    "\n",
    "Install SparseML with `pip`:\n",
    "\n",
    "```\n",
    "pip install sparseml[torchvision]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad80edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sparseml\n",
    "import torchvision\n",
    "from sparseml.pytorch.optim import ScheduledModifierManager\n",
    "from sparseml.pytorch.utils import TensorBoardLogger, ModuleExporter, get_prunable_layers, tensor_sparsity\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01779bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a128dcc",
   "metadata": {},
   "source": [
    "## **Step 1: Setup Dataset**\n",
    "\n",
    "Oxford 102 Flower is an image classification dataset consisting of 102 flower categories. The flowers were chosen to be flowers commonly occurring in the United Kingdom. Each class consists of between 40 and 258 images. The images have large scale, pose and light variations. In addition, there are categories that have large variations within the category, and several very similar categories.\n",
    "\n",
    "We use the standard PyTorch `datasets` and `dataloaders` to manage the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d180bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763bac85aa6a4428a625456fc126a409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344862509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71f7bc3f1e8471a89d7d59588199ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369730d018144b9b973264730f6c502d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_LABELS = 102\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# imagenet transforms\n",
    "imagenet_transform = transforms.Compose([\n",
    "   transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, max_size=None, antialias=None),\n",
    "   transforms.CenterCrop(size=(224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# datasets\n",
    "train_dataset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\",\n",
    "    split=\"train\",\n",
    "    transform=imagenet_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\",\n",
    "    split=\"val\",\n",
    "    transform=imagenet_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=16)\n",
    "val_loader = DataLoader(val_dataset, BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890cca4a",
   "metadata": {},
   "source": [
    "## Step 2: Setup PyTorch Training Loop\n",
    "\n",
    "We will use this training loop below. This is standard PyTorch functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1b878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "def run_model_one_epoch(model, data_loader, criterion, device, train=False, optimizer=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # loop through batches\n",
    "    for step, (inputs, labels) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # compute loss, run backpropogation\n",
    "        outputs = model(inputs)  # model returns logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # run evaluation\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        total_correct += torch.sum(predictions == labels).item()\n",
    "        total_predictions += inputs.size(0)\n",
    "\n",
    "    # return loss and evaluation metric\n",
    "    loss = running_loss / (step + 1.0)\n",
    "    accuracy = total_correct / total_predictions\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385497a",
   "metadata": {},
   "source": [
    "## **Step 3: Train DenseNet121 on Flowers102**\n",
    "\n",
    "First, we will train a dense version of DenseNet121 on the Flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d554578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download pre-trained model, setup classification head\n",
    "model = torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, NUM_LABELS)\n",
    "model.to(device)\n",
    "\n",
    "# setup loss function and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=8e-3) # lr will be override by sparseml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb400dc3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Next, we will use SparseML's recipes to set the hyperparameters of training loop. In this case, we will use the following recipe:\n",
    "\n",
    "```yaml\n",
    "# Epoch and Learning-Rate variables\n",
    "num_epochs: 15.0\n",
    "init_lr: 0.001\n",
    "\n",
    "training_modifiers:\n",
    "  - !EpochRangeModifier\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "\n",
    "  - !LearningRateFunctionModifier\n",
    "    final_lr: 0.0\n",
    "    init_lr: eval(init_lr)\n",
    "    lr_func: cosine\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "```\n",
    "\n",
    "As you can see, the recipe includes an `!EpochRangeModifier` and a `!LearningRateFunctionModifier`. These modifiers simply set the number of epochs to train for and the learning rate schedule. As a result, the final model will be dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6a53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_recipe_path = \"./recipe.dense.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8653c9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch and Learning-Rate variables\r\n",
      "num_epochs: 15.0\r\n",
      "init_lr: 0.001\r\n",
      "\r\n",
      "training_modifiers:\r\n",
      "  - !EpochRangeModifier\r\n",
      "    start_epoch: 0.0\r\n",
      "    end_epoch: eval(num_epochs)\r\n",
      "\r\n",
      "  - !LearningRateFunctionModifier\r\n",
      "    final_lr: 0.0\r\n",
      "    init_lr: eval(init_lr)\r\n",
      "    lr_func: cosine\r\n",
      "    start_epoch: 0.0\r\n",
      "    end_epoch: eval(num_epochs)"
     ]
    }
   ],
   "source": [
    "!cat ./recipe.dense.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aed1b",
   "metadata": {},
   "source": [
    "Next, we use SparseML's `ScheduledModifierManager` to parse and apply the recipe. The `manager.modify` function modifies and wraps the `model` and `optimizer` with the instructions from the recipe. You can use the `model` and `optimizer` just like standard PyTorch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1749e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ScheduledModifierManager and Optimizer wrapper\n",
    "manager = ScheduledModifierManager.from_yaml(dense_recipe_path)\n",
    "optimizer = manager.modify(model, optimizer, steps_per_epoch=len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67c917",
   "metadata": {},
   "source": [
    "Kick off the transfer learning loop. Our run reached ~91% validation accuracy after 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00d175b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Training Epoch 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc102107fa14b86a4a30b24e5d7b405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1/15\n",
      "Training Loss: 4.19914660602808\n",
      "Top 1 Acc: 0.1264705882352941\n",
      "\n",
      "Running Validation Epoch 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0ecec9c2424325a01df32be6f21418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 1/15\n",
      "Val Loss: 3.301237178966403\n",
      "Top 1 Acc: 0.23431372549019608\n",
      "\n",
      "Running Training Epoch 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6005450fac54684befac08824fb177f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2/15\n",
      "Training Loss: 2.2919996976852417\n",
      "Top 1 Acc: 0.43333333333333335\n",
      "\n",
      "Running Validation Epoch 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88308d3c3bbc4e21a181389c9ed99e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 2/15\n",
      "Val Loss: 1.696666894480586\n",
      "Top 1 Acc: 0.5813725490196079\n",
      "\n",
      "Running Training Epoch 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db016e4fe9e4ffa830f286d30f991f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3/15\n",
      "Training Loss: 1.2627511247992516\n",
      "Top 1 Acc: 0.6941176470588235\n",
      "\n",
      "Running Validation Epoch 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20302fb50d414a40a077f6f86642114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 3/15\n",
      "Val Loss: 1.2215265250997618\n",
      "Top 1 Acc: 0.6705882352941176\n",
      "\n",
      "Running Training Epoch 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1884c41d84d159f9dcbf804780fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4/15\n",
      "Training Loss: 0.6234219996258616\n",
      "Top 1 Acc: 0.8715686274509804\n",
      "\n",
      "Running Validation Epoch 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db591064f413463f94bdbfba2f8f7a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 4/15\n",
      "Val Loss: 0.8702319986768998\n",
      "Top 1 Acc: 0.7725490196078432\n",
      "\n",
      "Running Training Epoch 5/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e891b1924fa449318219ba42c1b0adbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 5/15\n",
      "Training Loss: 0.25333422678522766\n",
      "Top 1 Acc: 0.9715686274509804\n",
      "\n",
      "Running Validation Epoch 5/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daefa3d2ed148c69410b5182b7c1540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 5/15\n",
      "Val Loss: 0.6484642465366051\n",
      "Top 1 Acc: 0.8303921568627451\n",
      "\n",
      "Running Training Epoch 6/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e67b147320944348a7a24520e7bd4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 6/15\n",
      "Training Loss: 0.11867174645885825\n",
      "Top 1 Acc: 0.9911764705882353\n",
      "\n",
      "Running Validation Epoch 6/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2ab925243d4c49a5ca036f429af265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 6/15\n",
      "Val Loss: 0.48386382311582565\n",
      "Top 1 Acc: 0.8794117647058823\n",
      "\n",
      "Running Training Epoch 7/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3c4fde8aca45deacf8de80545c25dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 7/15\n",
      "Training Loss: 0.054829225555295125\n",
      "Top 1 Acc: 0.9980392156862745\n",
      "\n",
      "Running Validation Epoch 7/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfad2d14a7af473e86ff94dcae0bfd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 7/15\n",
      "Val Loss: 0.440820337695186\n",
      "Top 1 Acc: 0.8872549019607843\n",
      "\n",
      "Running Training Epoch 8/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a48624fb9c42c483e41a24fd75ec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 8/15\n",
      "Training Loss: 0.028182140173157677\n",
      "Top 1 Acc: 0.9990196078431373\n",
      "\n",
      "Running Validation Epoch 8/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649345e9f7bd4186acfe485cadecb295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 8/15\n",
      "Val Loss: 0.4080205729769659\n",
      "Top 1 Acc: 0.8960784313725491\n",
      "\n",
      "Running Training Epoch 9/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cd24bf46b04ac89c0b4ff15cc9bafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 9/15\n",
      "Training Loss: 0.021117904645507224\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 9/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9a1881d6664dd1b5bdfa2823bf9148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 9/15\n",
      "Val Loss: 0.38095567109121475\n",
      "Top 1 Acc: 0.903921568627451\n",
      "\n",
      "Running Training Epoch 10/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c0c2f829b444e8bcaae599cfde4ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10/15\n",
      "Training Loss: 0.014984913424996193\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 10/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89859df88d664b1fb0058881df0c5e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 10/15\n",
      "Val Loss: 0.37495101936656283\n",
      "Top 1 Acc: 0.9029411764705882\n",
      "\n",
      "Running Training Epoch 11/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db77e11719c74c618871a585a82eb638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 11/15\n",
      "Training Loss: 0.013377375871641561\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 11/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6e32b2f92b4706b4062c5fb67cac0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 11/15\n",
      "Val Loss: 0.3680900867911987\n",
      "Top 1 Acc: 0.9049019607843137\n",
      "\n",
      "Running Training Epoch 12/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec404dba97e642e9a2ad72f449a38657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 12/15\n",
      "Training Loss: 0.012655298603931442\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 12/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56615278976e4e76ad65a5f89b06cab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 12/15\n",
      "Val Loss: 0.3580578453402268\n",
      "Top 1 Acc: 0.9068627450980392\n",
      "\n",
      "Running Training Epoch 13/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0617af431250496e83bef2e25e41ad24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 13/15\n",
      "Training Loss: 0.01083394562738249\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 13/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288df8f0a45941938c577ae99a268b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 13/15\n",
      "Val Loss: 0.3625864443529281\n",
      "Top 1 Acc: 0.9107843137254902\n",
      "\n",
      "Running Training Epoch 14/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337c24a6388343ae8104548d23ff67bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 14/15\n",
      "Training Loss: 0.011353839217917994\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 14/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9455319c9cf34f5f9c8a4d946168e029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 14/15\n",
      "Val Loss: 0.3596206047659507\n",
      "Top 1 Acc: 0.9068627450980392\n",
      "\n",
      "Running Training Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bc0349cd17470389fb7ef6a4f83580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 15/15\n",
      "Training Loss: 0.011049875349272043\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e95a8d6ae1841d5a4b3d8b1272ccf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 15/15\n",
      "Val Loss: 0.36176005096785957\n",
      "Top 1 Acc: 0.9058823529411765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "for epoch in range(manager.max_epochs):\n",
    "    # run training loop\n",
    "    epoch_name = f\"{epoch + 1}/{manager.max_epochs}\"\n",
    "    \n",
    "    print(f\"Running Training Epoch {epoch_name}\")\n",
    "    train_loss, train_acc = run_model_one_epoch(model, train_loader, criterion, device, train=True, optimizer=optimizer)\n",
    "    print(f\"Training Epoch: {epoch_name}\\nTraining Loss: {train_loss}\\nTop 1 Acc: {train_acc}\\n\")\n",
    "\n",
    "    # run validation loop\n",
    "    print(f\"Running Validation Epoch {epoch_name}\")\n",
    "    val_loss, val_acc = run_model_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Epoch: {epoch_name}\\nVal Loss: {val_loss}\\nTop 1 Acc: {val_acc}\\n\")\n",
    "\n",
    "# clean up\n",
    "manager.finalize(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3d14e",
   "metadata": {},
   "source": [
    "Export the model in case we want to reload in the future, so we do not have to rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fa4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/rshaw/python-venvs/sparseml-env/lib/python3.8/site-packages/torch/onnx/utils.py:439: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"densenet-models\"\n",
    "exporter = ModuleExporter(model, output_dir=save_dir)\n",
    "exporter.export_pytorch(name=\"dense-model.pth\")\n",
    "exporter.export_onnx(torch.randn(1, 3, 224, 224), name=\"dense-model.onnx\", convert_qat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4532442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d6309",
   "metadata": {},
   "source": [
    "## Step 4: Prune The Model\n",
    "\n",
    "With a model trained on Flowers, we are now ready to apply the GMP algorithm to prune the model. The GMP algorithm is an interative pruning algorithm. At the end of each epoch, we identify the lowest magnitude weights (those closest to 0) and remove them from the network starting from an initial level of sparsity until a final level of sparsity. The remaining nonzero weights are then fine-tuned onto training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8447d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load the trained model from Part 3\n",
    "checkpoint = torch.load(\"./densenet-models/training/dense-model.pth\")\n",
    "model = torchvision.models.densenet121()\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, NUM_LABELS)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# setup loss function and optimizer, LR will be overriden by sparseml\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=8e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05d884",
   "metadata": {},
   "source": [
    "Next, we need to create a SparseML recipe which includes the GMP algorithm. The `!GlobalMagnitudePruningModifier` modifier instructs SparseML to apply the GMP algorithm at a global level (pruning the lowest magnitude weights across all layers).\n",
    "\n",
    "Firstly, we need to decide identify which parameters of the model to apply the GMP algorithm to. We can use the `get_prunable_layers` function to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d367905a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.conv0\n",
      "features.denseblock1.denselayer1.conv1\n",
      "features.denseblock1.denselayer1.conv2\n",
      "features.denseblock1.denselayer2.conv1\n",
      "features.denseblock1.denselayer2.conv2\n",
      "features.denseblock1.denselayer3.conv1\n",
      "features.denseblock1.denselayer3.conv2\n",
      "features.denseblock1.denselayer4.conv1\n",
      "features.denseblock1.denselayer4.conv2\n",
      "features.denseblock1.denselayer5.conv1\n",
      "features.denseblock1.denselayer5.conv2\n",
      "features.denseblock1.denselayer6.conv1\n",
      "features.denseblock1.denselayer6.conv2\n",
      "features.transition1.conv\n",
      "features.denseblock2.denselayer1.conv1\n",
      "features.denseblock2.denselayer1.conv2\n",
      "features.denseblock2.denselayer2.conv1\n",
      "features.denseblock2.denselayer2.conv2\n",
      "features.denseblock2.denselayer3.conv1\n",
      "features.denseblock2.denselayer3.conv2\n",
      "features.denseblock2.denselayer4.conv1\n",
      "features.denseblock2.denselayer4.conv2\n",
      "features.denseblock2.denselayer5.conv1\n",
      "features.denseblock2.denselayer5.conv2\n",
      "features.denseblock2.denselayer6.conv1\n",
      "features.denseblock2.denselayer6.conv2\n",
      "features.denseblock2.denselayer7.conv1\n",
      "features.denseblock2.denselayer7.conv2\n",
      "features.denseblock2.denselayer8.conv1\n",
      "features.denseblock2.denselayer8.conv2\n",
      "features.denseblock2.denselayer9.conv1\n",
      "features.denseblock2.denselayer9.conv2\n",
      "features.denseblock2.denselayer10.conv1\n",
      "features.denseblock2.denselayer10.conv2\n",
      "features.denseblock2.denselayer11.conv1\n",
      "features.denseblock2.denselayer11.conv2\n",
      "features.denseblock2.denselayer12.conv1\n",
      "features.denseblock2.denselayer12.conv2\n",
      "features.transition2.conv\n",
      "features.denseblock3.denselayer1.conv1\n",
      "features.denseblock3.denselayer1.conv2\n",
      "features.denseblock3.denselayer2.conv1\n",
      "features.denseblock3.denselayer2.conv2\n",
      "features.denseblock3.denselayer3.conv1\n",
      "features.denseblock3.denselayer3.conv2\n",
      "features.denseblock3.denselayer4.conv1\n",
      "features.denseblock3.denselayer4.conv2\n",
      "features.denseblock3.denselayer5.conv1\n",
      "features.denseblock3.denselayer5.conv2\n",
      "features.denseblock3.denselayer6.conv1\n",
      "features.denseblock3.denselayer6.conv2\n",
      "features.denseblock3.denselayer7.conv1\n",
      "features.denseblock3.denselayer7.conv2\n",
      "features.denseblock3.denselayer8.conv1\n",
      "features.denseblock3.denselayer8.conv2\n",
      "features.denseblock3.denselayer9.conv1\n",
      "features.denseblock3.denselayer9.conv2\n",
      "features.denseblock3.denselayer10.conv1\n",
      "features.denseblock3.denselayer10.conv2\n",
      "features.denseblock3.denselayer11.conv1\n",
      "features.denseblock3.denselayer11.conv2\n",
      "features.denseblock3.denselayer12.conv1\n",
      "features.denseblock3.denselayer12.conv2\n",
      "features.denseblock3.denselayer13.conv1\n",
      "features.denseblock3.denselayer13.conv2\n",
      "features.denseblock3.denselayer14.conv1\n",
      "features.denseblock3.denselayer14.conv2\n",
      "features.denseblock3.denselayer15.conv1\n",
      "features.denseblock3.denselayer15.conv2\n",
      "features.denseblock3.denselayer16.conv1\n",
      "features.denseblock3.denselayer16.conv2\n",
      "features.denseblock3.denselayer17.conv1\n",
      "features.denseblock3.denselayer17.conv2\n",
      "features.denseblock3.denselayer18.conv1\n",
      "features.denseblock3.denselayer18.conv2\n",
      "features.denseblock3.denselayer19.conv1\n",
      "features.denseblock3.denselayer19.conv2\n",
      "features.denseblock3.denselayer20.conv1\n",
      "features.denseblock3.denselayer20.conv2\n",
      "features.denseblock3.denselayer21.conv1\n",
      "features.denseblock3.denselayer21.conv2\n",
      "features.denseblock3.denselayer22.conv1\n",
      "features.denseblock3.denselayer22.conv2\n",
      "features.denseblock3.denselayer23.conv1\n",
      "features.denseblock3.denselayer23.conv2\n",
      "features.denseblock3.denselayer24.conv1\n",
      "features.denseblock3.denselayer24.conv2\n",
      "features.transition3.conv\n",
      "features.denseblock4.denselayer1.conv1\n",
      "features.denseblock4.denselayer1.conv2\n",
      "features.denseblock4.denselayer2.conv1\n",
      "features.denseblock4.denselayer2.conv2\n",
      "features.denseblock4.denselayer3.conv1\n",
      "features.denseblock4.denselayer3.conv2\n",
      "features.denseblock4.denselayer4.conv1\n",
      "features.denseblock4.denselayer4.conv2\n",
      "features.denseblock4.denselayer5.conv1\n",
      "features.denseblock4.denselayer5.conv2\n",
      "features.denseblock4.denselayer6.conv1\n",
      "features.denseblock4.denselayer6.conv2\n",
      "features.denseblock4.denselayer7.conv1\n",
      "features.denseblock4.denselayer7.conv2\n",
      "features.denseblock4.denselayer8.conv1\n",
      "features.denseblock4.denselayer8.conv2\n",
      "features.denseblock4.denselayer9.conv1\n",
      "features.denseblock4.denselayer9.conv2\n",
      "features.denseblock4.denselayer10.conv1\n",
      "features.denseblock4.denselayer10.conv2\n",
      "features.denseblock4.denselayer11.conv1\n",
      "features.denseblock4.denselayer11.conv2\n",
      "features.denseblock4.denselayer12.conv1\n",
      "features.denseblock4.denselayer12.conv2\n",
      "features.denseblock4.denselayer13.conv1\n",
      "features.denseblock4.denselayer13.conv2\n",
      "features.denseblock4.denselayer14.conv1\n",
      "features.denseblock4.denselayer14.conv2\n",
      "features.denseblock4.denselayer15.conv1\n",
      "features.denseblock4.denselayer15.conv2\n",
      "features.denseblock4.denselayer16.conv1\n",
      "features.denseblock4.denselayer16.conv2\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "for (name, layer) in get_prunable_layers(model):\n",
    "    print(f\"{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fa136",
   "metadata": {},
   "source": [
    "We will apply GMP to all layers with `__ALL_PRUNABLE__`. Here is what the recipe looks like:\n",
    "\n",
    "```yaml\n",
    "# Epoch hyperparams\n",
    "stabilization_epochs: 1.0\n",
    "pruning_epochs: 9.0\n",
    "finetuning_epochs: 5.0\n",
    "\n",
    "# Learning rate hyperparams\n",
    "init_lr: 0.0001\n",
    "final_lr: 0.00005\n",
    "\n",
    "# Pruning hyperparams\n",
    "init_sparsity: 0.05\n",
    "final_sparsity: 0.9\n",
    "\n",
    "# Stabalization Stage\n",
    "training_modifiers:\n",
    "  - !EpochRangeModifier\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)\n",
    "\n",
    "  - !SetLearningRateModifier\n",
    "    start_epoch: 0.0\n",
    "    learning_rate: eval(init_lr)\n",
    "\n",
    "# Pruning Stage\n",
    "pruning_modifiers:\n",
    "  - !LearningRateFunctionModifier\n",
    "    init_lr: eval(init_lr)\n",
    "    final_lr: eval(final_lr)\n",
    "    lr_func: cosine\n",
    "    start_epoch: eval(stabilization_epochs)\n",
    "    end_epoch: eval(stabilization_epochs + pruning_epochs)\n",
    "\n",
    "  - !GlobalMagnitudePruningModifier\n",
    "    init_sparsity: eval(init_sparsity)\n",
    "    final_sparsity: eval(final_sparsity)\n",
    "    start_epoch: eval(stabilization_epochs)\n",
    "    end_epoch: eval(stabilization_epochs + pruning_epochs)\n",
    "    update_frequency: 0.5\n",
    "    params: __ALL_PRUNABLE__\n",
    "    leave_enabled: True\n",
    "\n",
    "# Finetuning Stage\n",
    "finetuning_modifiers:\n",
    "  - !LearningRateFunctionModifier\n",
    "    init_lr: eval(init_lr)\n",
    "    final_lr: eval(final_lr)\n",
    "    lr_func: cosine\n",
    "    start_epoch: eval(stabilization_epochs + pruning_epochs)\n",
    "    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)\n",
    "```\n",
    "\n",
    "This recipe specifies that we will run the GMP algorithm for the first 10 epochs. We start at an `init_sparsity` level of 5% and gradually increase sparsity to a `final_sparsity` level of 90% following a `cubic` curve across each of the layers in the network.\n",
    "\n",
    "Over the next 5 epochs, we fine-tune the 90% pruned model further. Since we set `leave_enabled=True` the sparsity level will be maintained as the fine-tuning occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8518b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_recipe_path = \"./recipe.prune.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b17fc31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch hyperparams\r\n",
      "stabilization_epochs: 1.0\r\n",
      "pruning_epochs: 9.0\r\n",
      "finetuning_epochs: 5.0\r\n",
      "\r\n",
      "# Learning rate hyperparams\r\n",
      "init_lr: 0.0001\r\n",
      "final_lr: 0.00005\r\n",
      "\r\n",
      "# Pruning hyperparams\r\n",
      "init_sparsity: 0.05\r\n",
      "final_sparsity: 0.9\r\n",
      "\r\n",
      "# Stabalization Stage\r\n",
      "training_modifiers:\r\n",
      "  - !EpochRangeModifier\r\n",
      "    start_epoch: 0.0\r\n",
      "    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)\r\n",
      "\r\n",
      "  - !SetLearningRateModifier\r\n",
      "    start_epoch: 0.0\r\n",
      "    learning_rate: eval(init_lr)\r\n",
      "\r\n",
      "# Pruning Stage\r\n",
      "pruning_modifiers:\r\n",
      "  - !LearningRateFunctionModifier\r\n",
      "    init_lr: eval(init_lr)\r\n",
      "    final_lr: eval(final_lr)\r\n",
      "    lr_func: cosine\r\n",
      "    start_epoch: eval(stabilization_epochs)\r\n",
      "    end_epoch: eval(stabilization_epochs + pruning_epochs)\r\n",
      "\r\n",
      "  - !GlobalMagnitudePruningModifier\r\n",
      "    init_sparsity: eval(init_sparsity)\r\n",
      "    final_sparsity: eval(final_sparsity)\r\n",
      "    start_epoch: eval(stabilization_epochs)\r\n",
      "    end_epoch: eval(stabilization_epochs + pruning_epochs)\r\n",
      "    update_frequency: 0.5\r\n",
      "    params: __ALL_PRUNABLE__\r\n",
      "    leave_enabled: True\r\n",
      "\r\n",
      "# Finetuning Stage\r\n",
      "finetuning_modifiers:\r\n",
      "  - !LearningRateFunctionModifier\r\n",
      "    init_lr: eval(init_lr)\r\n",
      "    final_lr: eval(final_lr)\r\n",
      "    lr_func: cosine\r\n",
      "    start_epoch: eval(stabilization_epochs + pruning_epochs)\r\n",
      "    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)"
     ]
    }
   ],
   "source": [
    "!cat ./recipe.prune.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68646bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ScheduledModifierManager and Optimizer wrapper\n",
    "manager = ScheduledModifierManager.from_yaml(pruning_recipe_path)\n",
    "logger = TensorBoardLogger(log_path=\"./tensorboard_outputs/densenet/pruning-run\")\n",
    "optimizer = manager.modify(model, optimizer, loggers=[logger], steps_per_epoch=len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a5909",
   "metadata": {},
   "source": [
    "Next, kick off the GMP training loop. \n",
    "\n",
    "As you can see, we use the wrapped `optimizer` and `model` in the same way as above. SparseML parsed the recipe and updated the `optimizer` with the logic of GMP algorithm from the recipe. This allows you to use the `optimizer` and `model` as usual, with all of the pruning-related logic handled by SparseML.\n",
    "\n",
    "Our 90% pruned model reaches ~90% validation accuracy (vs ~90% for the dense model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "601c8c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Training Epoch 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8353532ae004b9799a0410962b228e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1/15\n",
      "Training Loss: 0.010088199924211949\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a356d4b60a413396b0958ae1a315c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 1/15\n",
      "Val Loss: 0.3916410197271034\n",
      "Top 1 Acc: 0.8980392156862745\n",
      "\n",
      "Running Training Epoch 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69bec2b1c074834acb8ecd1ab9ea1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2/15\n",
      "Training Loss: 0.006311728560831398\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dd0fdfcd584a2f930b0fa6d4610d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 2/15\n",
      "Val Loss: 0.35422829847630055\n",
      "Top 1 Acc: 0.9147058823529411\n",
      "\n",
      "Running Training Epoch 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f0f96cdf524396a32913c870789586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3/15\n",
      "Training Loss: 0.00590914695567335\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e760e7254fa451b84237d08849bcca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 3/15\n",
      "Val Loss: 0.3660663195678353\n",
      "Top 1 Acc: 0.8970588235294118\n",
      "\n",
      "Running Training Epoch 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf73db4609e453faade223ff9adbcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4/15\n",
      "Training Loss: 0.006236200162675232\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa884ce94b444ba2b9c2bad761a8e382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 4/15\n",
      "Val Loss: 0.34212215257866774\n",
      "Top 1 Acc: 0.9137254901960784\n",
      "\n",
      "Running Training Epoch 5/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada5d977510f445bb4fa544455ab8232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 5/15\n",
      "Training Loss: 0.01890451288272743\n",
      "Top 1 Acc: 0.9990196078431373\n",
      "\n",
      "Running Validation Epoch 5/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6392c0b7c9a4a9a9bf168eb3ec163c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 5/15\n",
      "Val Loss: 0.35794301797432126\n",
      "Top 1 Acc: 0.9098039215686274\n",
      "\n",
      "Running Training Epoch 6/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b43afe59c946faa83f8cd1308e431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 6/15\n",
      "Training Loss: 0.046258137284894474\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 6/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32b64a8d92b411c9d318d3b470a6a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 6/15\n",
      "Val Loss: 0.4052634066902101\n",
      "Top 1 Acc: 0.8990196078431373\n",
      "\n",
      "Running Training Epoch 7/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debd438be160481d9462ccfd11d3243c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 7/15\n",
      "Training Loss: 0.08744520283653401\n",
      "Top 1 Acc: 0.9970588235294118\n",
      "\n",
      "Running Validation Epoch 7/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b88e2e7ef84a6a86b272c79da9000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 7/15\n",
      "Val Loss: 0.45730660887784325\n",
      "Top 1 Acc: 0.8990196078431373\n",
      "\n",
      "Running Training Epoch 8/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcdd24987fc4eed96213c04d4577282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 8/15\n",
      "Training Loss: 0.1278208080912009\n",
      "Top 1 Acc: 0.9980392156862745\n",
      "\n",
      "Running Validation Epoch 8/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9e0cdbd5524f008c929ebcc8a7dbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 8/15\n",
      "Val Loss: 0.5031384860631078\n",
      "Top 1 Acc: 0.8990196078431373\n",
      "\n",
      "Running Training Epoch 9/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e48cd32faa424ba9f7c361991e54bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 9/15\n",
      "Training Loss: 0.12604948785156012\n",
      "Top 1 Acc: 0.9970588235294118\n",
      "\n",
      "Running Validation Epoch 9/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1094557dc40144cbace73bf9cecaeda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 9/15\n",
      "Val Loss: 0.5122074343380518\n",
      "Top 1 Acc: 0.888235294117647\n",
      "\n",
      "Running Training Epoch 10/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ea432fcfd5464db2aeb2afb5c0b4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10/15\n",
      "Training Loss: 0.0988512066542171\n",
      "Top 1 Acc: 0.9990196078431373\n",
      "\n",
      "Running Validation Epoch 10/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d994e85e7f544867b08fc78eaa0ca10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 10/15\n",
      "Val Loss: 0.4836790200206451\n",
      "Top 1 Acc: 0.8970588235294118\n",
      "\n",
      "Running Training Epoch 11/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640434ea2ad6411292385fc142c31923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 11/15\n",
      "Training Loss: 0.06858557235682383\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 11/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a530cc819634b8499141e37e8356ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 11/15\n",
      "Val Loss: 0.4598175589344464\n",
      "Top 1 Acc: 0.8911764705882353\n",
      "\n",
      "Running Training Epoch 12/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da09e4c522e74fa299aa5cc09ab2169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 12/15\n",
      "Training Loss: 0.05144688946893439\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 12/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab37143a56d64a0f9a873b9616c45a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 12/15\n",
      "Val Loss: 0.4425734535616357\n",
      "Top 1 Acc: 0.8990196078431373\n",
      "\n",
      "Running Training Epoch 13/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258c9e484a474f468248973cf97548a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 13/15\n",
      "Training Loss: 0.04289846486062743\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 13/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2991c197124094a2a068cdd3409b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 13/15\n",
      "Val Loss: 0.4277399673592299\n",
      "Top 1 Acc: 0.9029411764705882\n",
      "\n",
      "Running Training Epoch 14/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e08525fe684810a324de0f4a96b699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 14/15\n",
      "Training Loss: 0.04066189884906635\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 14/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f34a3da7ffc4103a09e314f6c2331ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 14/15\n",
      "Val Loss: 0.41972393746254966\n",
      "Top 1 Acc: 0.9058823529411765\n",
      "\n",
      "Running Training Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21798cc084c4eabbb9eca82ad1a17ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 15/15\n",
      "Training Loss: 0.032934420625679195\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbd08dd2da04861ac0506ef1ed878b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 15/15\n",
      "Val Loss: 0.4125456868932815\n",
      "Top 1 Acc: 0.903921568627451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run GMP algorithm\n",
    "epoch = 0\n",
    "for epoch in range(manager.max_epochs):\n",
    "    # run training loop\n",
    "    epoch_name = f\"{epoch + 1}/{manager.max_epochs}\"\n",
    "    \n",
    "    print(f\"Running Training Epoch {epoch_name}\")\n",
    "    train_loss, train_acc = run_model_one_epoch(model, train_loader, criterion, device, train=True, optimizer=optimizer)\n",
    "    print(f\"Training Epoch: {epoch_name}\\nTraining Loss: {train_loss}\\nTop 1 Acc: {train_acc}\\n\")\n",
    "\n",
    "    # run validation loop\n",
    "    print(f\"Running Validation Epoch {epoch_name}\")\n",
    "    val_loss, val_acc = run_model_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Epoch: {epoch_name}\\nVal Loss: {val_loss}\\nTop 1 Acc: {val_acc}\\n\")\n",
    "    \n",
    "    logger.log_scalar(\"Metrics/Loss (Train)\", train_loss, epoch)\n",
    "    logger.log_scalar(\"Metrics/Accuracy (Train)\", train_acc, epoch)\n",
    "    logger.log_scalar(\"Metrics/Loss (Validation)\", val_loss, epoch)\n",
    "    logger.log_scalar(\"Metrics/Accuracy (Validation)\", val_acc, epoch)\n",
    "\n",
    "manager.finalize(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c96232",
   "metadata": {},
   "source": [
    "The resulting model is is 90% sparse and quantized, while achieving validation accuracy of ~91% (vs the unoptimized dense model at ~91%) without much hyperparameter search. Key hyperparameter experiments you may want to run include:\n",
    "- Learning rate\n",
    "- Learning rate schedule\n",
    "- Sparsity level\n",
    "- Number of pruning epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5afa94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity By Layer:\n",
      "features.conv0.weight: 0.4854\n",
      "features.denseblock1.denselayer1.conv1.weight: 0.7532\n",
      "features.denseblock1.denselayer1.conv2.weight: 0.8345\n",
      "features.denseblock1.denselayer2.conv1.weight: 0.7559\n",
      "features.denseblock1.denselayer2.conv2.weight: 0.8695\n",
      "features.denseblock1.denselayer3.conv1.weight: 0.7667\n",
      "features.denseblock1.denselayer3.conv2.weight: 0.8346\n",
      "features.denseblock1.denselayer4.conv1.weight: 0.8263\n",
      "features.denseblock1.denselayer4.conv2.weight: 0.8363\n",
      "features.denseblock1.denselayer5.conv1.weight: 0.8754\n",
      "features.denseblock1.denselayer5.conv2.weight: 0.8869\n",
      "features.denseblock1.denselayer6.conv1.weight: 0.8501\n",
      "features.denseblock1.denselayer6.conv2.weight: 0.8444\n",
      "features.transition1.conv.weight: 0.7236\n",
      "features.denseblock2.denselayer1.conv1.weight: 0.9351\n",
      "features.denseblock2.denselayer1.conv2.weight: 0.8903\n",
      "features.denseblock2.denselayer2.conv1.weight: 0.8870\n",
      "features.denseblock2.denselayer2.conv2.weight: 0.8632\n",
      "features.denseblock2.denselayer3.conv1.weight: 0.8878\n",
      "features.denseblock2.denselayer3.conv2.weight: 0.8505\n",
      "features.denseblock2.denselayer4.conv1.weight: 0.8665\n",
      "features.denseblock2.denselayer4.conv2.weight: 0.8668\n",
      "features.denseblock2.denselayer5.conv1.weight: 0.8973\n",
      "features.denseblock2.denselayer5.conv2.weight: 0.8542\n",
      "features.denseblock2.denselayer6.conv1.weight: 0.9113\n",
      "features.denseblock2.denselayer6.conv2.weight: 0.8672\n",
      "features.denseblock2.denselayer7.conv1.weight: 0.8821\n",
      "features.denseblock2.denselayer7.conv2.weight: 0.8752\n",
      "features.denseblock2.denselayer8.conv1.weight: 0.8909\n",
      "features.denseblock2.denselayer8.conv2.weight: 0.8652\n",
      "features.denseblock2.denselayer9.conv1.weight: 0.9029\n",
      "features.denseblock2.denselayer9.conv2.weight: 0.8796\n",
      "features.denseblock2.denselayer10.conv1.weight: 0.8776\n",
      "features.denseblock2.denselayer10.conv2.weight: 0.8835\n",
      "features.denseblock2.denselayer11.conv1.weight: 0.8895\n",
      "features.denseblock2.denselayer11.conv2.weight: 0.8918\n",
      "features.denseblock2.denselayer12.conv1.weight: 0.8789\n",
      "features.denseblock2.denselayer12.conv2.weight: 0.9006\n",
      "features.transition2.conv.weight: 0.7790\n",
      "features.denseblock3.denselayer1.conv1.weight: 0.9173\n",
      "features.denseblock3.denselayer1.conv2.weight: 0.9001\n",
      "features.denseblock3.denselayer2.conv1.weight: 0.9390\n",
      "features.denseblock3.denselayer2.conv2.weight: 0.9020\n",
      "features.denseblock3.denselayer3.conv1.weight: 0.9181\n",
      "features.denseblock3.denselayer3.conv2.weight: 0.9023\n",
      "features.denseblock3.denselayer4.conv1.weight: 0.9189\n",
      "features.denseblock3.denselayer4.conv2.weight: 0.8860\n",
      "features.denseblock3.denselayer5.conv1.weight: 0.9339\n",
      "features.denseblock3.denselayer5.conv2.weight: 0.8811\n",
      "features.denseblock3.denselayer6.conv1.weight: 0.9226\n",
      "features.denseblock3.denselayer6.conv2.weight: 0.8840\n",
      "features.denseblock3.denselayer7.conv1.weight: 0.9395\n",
      "features.denseblock3.denselayer7.conv2.weight: 0.8780\n",
      "features.denseblock3.denselayer8.conv1.weight: 0.9106\n",
      "features.denseblock3.denselayer8.conv2.weight: 0.8915\n",
      "features.denseblock3.denselayer9.conv1.weight: 0.9132\n",
      "features.denseblock3.denselayer9.conv2.weight: 0.8854\n",
      "features.denseblock3.denselayer10.conv1.weight: 0.9412\n",
      "features.denseblock3.denselayer10.conv2.weight: 0.8874\n",
      "features.denseblock3.denselayer11.conv1.weight: 0.9369\n",
      "features.denseblock3.denselayer11.conv2.weight: 0.8767\n",
      "features.denseblock3.denselayer12.conv1.weight: 0.9280\n",
      "features.denseblock3.denselayer12.conv2.weight: 0.8938\n",
      "features.denseblock3.denselayer13.conv1.weight: 0.9380\n",
      "features.denseblock3.denselayer13.conv2.weight: 0.8657\n",
      "features.denseblock3.denselayer14.conv1.weight: 0.9446\n",
      "features.denseblock3.denselayer14.conv2.weight: 0.8813\n",
      "features.denseblock3.denselayer15.conv1.weight: 0.9253\n",
      "features.denseblock3.denselayer15.conv2.weight: 0.8866\n",
      "features.denseblock3.denselayer16.conv1.weight: 0.9368\n",
      "features.denseblock3.denselayer16.conv2.weight: 0.9124\n",
      "features.denseblock3.denselayer17.conv1.weight: 0.9181\n",
      "features.denseblock3.denselayer17.conv2.weight: 0.8994\n",
      "features.denseblock3.denselayer18.conv1.weight: 0.9308\n",
      "features.denseblock3.denselayer18.conv2.weight: 0.8986\n",
      "features.denseblock3.denselayer19.conv1.weight: 0.9267\n",
      "features.denseblock3.denselayer19.conv2.weight: 0.8962\n",
      "features.denseblock3.denselayer20.conv1.weight: 0.9257\n",
      "features.denseblock3.denselayer20.conv2.weight: 0.9051\n",
      "features.denseblock3.denselayer21.conv1.weight: 0.9211\n",
      "features.denseblock3.denselayer21.conv2.weight: 0.8942\n",
      "features.denseblock3.denselayer22.conv1.weight: 0.9235\n",
      "features.denseblock3.denselayer22.conv2.weight: 0.8795\n",
      "features.denseblock3.denselayer23.conv1.weight: 0.9244\n",
      "features.denseblock3.denselayer23.conv2.weight: 0.9109\n",
      "features.denseblock3.denselayer24.conv1.weight: 0.9295\n",
      "features.denseblock3.denselayer24.conv2.weight: 0.9084\n",
      "features.transition3.conv.weight: 0.8512\n",
      "features.denseblock4.denselayer1.conv1.weight: 0.8777\n",
      "features.denseblock4.denselayer1.conv2.weight: 0.9108\n",
      "features.denseblock4.denselayer2.conv1.weight: 0.8745\n",
      "features.denseblock4.denselayer2.conv2.weight: 0.9407\n",
      "features.denseblock4.denselayer3.conv1.weight: 0.8852\n",
      "features.denseblock4.denselayer3.conv2.weight: 0.9220\n",
      "features.denseblock4.denselayer4.conv1.weight: 0.9029\n",
      "features.denseblock4.denselayer4.conv2.weight: 0.9377\n",
      "features.denseblock4.denselayer5.conv1.weight: 0.9003\n",
      "features.denseblock4.denselayer5.conv2.weight: 0.9536\n",
      "features.denseblock4.denselayer6.conv1.weight: 0.8978\n",
      "features.denseblock4.denselayer6.conv2.weight: 0.9540\n",
      "features.denseblock4.denselayer7.conv1.weight: 0.9109\n",
      "features.denseblock4.denselayer7.conv2.weight: 0.9555\n",
      "features.denseblock4.denselayer8.conv1.weight: 0.9142\n",
      "features.denseblock4.denselayer8.conv2.weight: 0.9557\n",
      "features.denseblock4.denselayer9.conv1.weight: 0.9185\n",
      "features.denseblock4.denselayer9.conv2.weight: 0.9599\n",
      "features.denseblock4.denselayer10.conv1.weight: 0.9184\n",
      "features.denseblock4.denselayer10.conv2.weight: 0.9595\n",
      "features.denseblock4.denselayer11.conv1.weight: 0.9204\n",
      "features.denseblock4.denselayer11.conv2.weight: 0.9610\n",
      "features.denseblock4.denselayer12.conv1.weight: 0.9226\n",
      "features.denseblock4.denselayer12.conv2.weight: 0.9612\n",
      "features.denseblock4.denselayer13.conv1.weight: 0.9257\n",
      "features.denseblock4.denselayer13.conv2.weight: 0.9609\n",
      "features.denseblock4.denselayer14.conv1.weight: 0.9281\n",
      "features.denseblock4.denselayer14.conv2.weight: 0.9596\n",
      "features.denseblock4.denselayer15.conv1.weight: 0.9292\n",
      "features.denseblock4.denselayer15.conv2.weight: 0.9615\n",
      "features.denseblock4.denselayer16.conv1.weight: 0.9256\n",
      "features.denseblock4.denselayer16.conv2.weight: 0.9572\n",
      "classifier.weight: 0.8164\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity By Layer:\")\n",
    "for (name, layer) in get_prunable_layers(model):\n",
    "    print(f\"{name}.weight: {tensor_sparsity(layer.weight).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44fb7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"densenet-models\"\n",
    "exporter = ModuleExporter(model, output_dir=save_dir)\n",
    "exporter.export_pytorch(name=\"pruned-model.pth\")\n",
    "exporter.export_onnx(torch.randn(1, 3, 224, 224), name=\"pruned-model.onnx\", convert_qat=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
